{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run .env and then it will make all the settings - thisd is a nice example to follow.\n",
    "%load_ext dotenv\n",
    "%dotenv ../src/.env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing?\n",
    "\n",
    "## Objectives\n",
    "\n",
    "\n",
    "* Build a data pipeline that downloads price data from the internet, stores it locally, transforms it into return data, and stores the feature set.\n",
    "    - Getting the data.\n",
    "    - Schemas and index in dask.\n",
    "\n",
    "* Explore the parquet format.\n",
    "    - Reading and writing parquet files.\n",
    "    - Read datasets that are stored in distributed files.\n",
    "    - Discuss dask vs pandas as a small example of big vs small data.\n",
    "    \n",
    "* Discuss the use of environment variables for settings.\n",
    "* Discuss how to use Jupyter notebooks and source code concurrently. \n",
    "* Logging and using a standard logger.\n",
    "\n",
    "## About the Data\n",
    "\n",
    "+ We will download the prices for a list of stocks.\n",
    "+ The source is Yahoo Finance and we will use the API provided by the library yfinance.\n",
    "\n",
    "\n",
    "## Medallion Architecture\n",
    "\n",
    "+ The architecture that we are thinking about is called Medallion by [DataBricks](https://www.databricks.com/glossary/medallion-architecture). It is an ELT type of thinking, although our data is well-structured.\n",
    "\n",
    "![Medallion Architecture (DataBicks)](./img/medallion-architecture.png)\n",
    "\n",
    "+ In our case, we would like to optimize the number of times that we download data from the internet. \n",
    "+ Ultimately, we will build a pipeline manager class that will help us control the process of obtaining and transforming our data.\n",
    "\n",
    "![](./img/target_pipeline_manager.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data from Yahoo Finance\n",
    "\n",
    "Yahoo Finance provides information about public stocks in different markets. The library yfinance gives us access to a fair bit of the data in Yahoo Finance. \n",
    "\n",
    "These steps are based on the instructions in:\n",
    "\n",
    "+ [yfinance documentation](https://pypi.org/project/yfinance/)\n",
    "+ [Tutorial in geeksforgeeks.org](https://www.geeksforgeeks.org/get-financial-data-from-yahoo-finance-with-python/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ If required, install: `python -m pip install yfinance`.\n",
    "+ To download the price history of a stock, first use the following setup:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yfinance\")\n",
    "\n",
    "sys.path.append(\"../src\") # add the src path to jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice in the code chunk above:\n",
    "\n",
    "+ Libraries are ordered from high-level to low-level libraries from the package manager (pip in this case, but could be conda, poetry, etc.)\n",
    "+ The command `sys.path.append(\"../src/)` will add the `../src/` directory to the path in the Notebook's kernel. This way, we can use our modules as part of the notebook.\n",
    "+ Local modules are imported at the end. \n",
    "+ The function `get_logger()` is called with `__name__` as recommended by the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to download the historical price data for a stock, we could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yfinance.Ticker object <AAPL>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf.Ticker(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.Ticker(\"AAPL\")\n",
    "px_dt = stock.history(start = \"2013-12-01\", end = \"2024-02-01\") # be careful with dating format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px_dt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-12-02 00:00:00-05:00', '2013-12-03 00:00:00-05:00',\n",
       "               '2013-12-04 00:00:00-05:00', '2013-12-05 00:00:00-05:00',\n",
       "               '2013-12-06 00:00:00-05:00', '2013-12-09 00:00:00-05:00',\n",
       "               '2013-12-10 00:00:00-05:00', '2013-12-11 00:00:00-05:00',\n",
       "               '2013-12-12 00:00:00-05:00', '2013-12-13 00:00:00-05:00',\n",
       "               ...\n",
       "               '2024-01-18 00:00:00-05:00', '2024-01-19 00:00:00-05:00',\n",
       "               '2024-01-22 00:00:00-05:00', '2024-01-23 00:00:00-05:00',\n",
       "               '2024-01-24 00:00:00-05:00', '2024-01-25 00:00:00-05:00',\n",
       "               '2024-01-26 00:00:00-05:00', '2024-01-29 00:00:00-05:00',\n",
       "               '2024-01-30 00:00:00-05:00', '2024-01-31 00:00:00-05:00'],\n",
       "              dtype='datetime64[ns, America/New_York]', name='Date', length=2558, freq=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px_dt.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametrize the download\n",
    "\n",
    "+ Generally, we will look to separate every parameter and setting from functions.\n",
    "+ If we had a few stocks, we could cycle through them. We need a place to store the list of tickers (a db or file, for example).\n",
    "+ Store a csv file with a few stock tickers. The location of the file is a setting, the contents of this file are parameters.\n",
    "+ Use **environment variables** to pass parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/tickers/sp500_wiki.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('TICKERS') # we are getting the right data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/tickers/sp500_wiki.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>20883</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>42942</td>\n",
       "      <td>91142</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>20883</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>41274</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>40730</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADBE</td>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Application Software</td>\n",
       "      <td>San Jose, California</td>\n",
       "      <td>35555</td>\n",
       "      <td>796343</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMD</td>\n",
       "      <td>Advanced Micro Devices</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>42814</td>\n",
       "      <td>2488</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AES</td>\n",
       "      <td>AES Corporation</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Independent Power Producers &amp; Energy Traders</td>\n",
       "      <td>Arlington, Virginia</td>\n",
       "      <td>36070</td>\n",
       "      <td>874761</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AFL</td>\n",
       "      <td>Aflac</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Life &amp; Health Insurance</td>\n",
       "      <td>Columbus, Georgia</td>\n",
       "      <td>36308</td>\n",
       "      <td>4977</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker                Security             GICS Sector  \\\n",
       "0    MMM                      3M             Industrials   \n",
       "1    AOS             A. O. Smith             Industrials   \n",
       "2    ABT                  Abbott             Health Care   \n",
       "3   ABBV                  AbbVie             Health Care   \n",
       "4    ACN               Accenture  Information Technology   \n",
       "5   ADBE              Adobe Inc.  Information Technology   \n",
       "6    AMD  Advanced Micro Devices  Information Technology   \n",
       "7    AES         AES Corporation               Utilities   \n",
       "8    AFL                   Aflac              Financials   \n",
       "\n",
       "                              GICS Sub-Industry    Headquarters Location  \\\n",
       "0                      Industrial Conglomerates    Saint Paul, Minnesota   \n",
       "1                             Building Products     Milwaukee, Wisconsin   \n",
       "2                         Health Care Equipment  North Chicago, Illinois   \n",
       "3                                 Biotechnology  North Chicago, Illinois   \n",
       "4                IT Consulting & Other Services          Dublin, Ireland   \n",
       "5                          Application Software     San Jose, California   \n",
       "6                                Semiconductors  Santa Clara, California   \n",
       "7  Independent Power Producers & Energy Traders      Arlington, Virginia   \n",
       "8                       Life & Health Insurance        Columbus, Georgia   \n",
       "\n",
       "   Date added      CIK      Founded  \n",
       "0       20883    66740         1902  \n",
       "1       42942    91142         1916  \n",
       "2       20883     1800         1888  \n",
       "3       41274  1551152  2013 (1888)  \n",
       "4       40730  1467373         1989  \n",
       "5       35555   796343         1982  \n",
       "6       42814     2488         1969  \n",
       "7       36070   874761         1981  \n",
       "8       36308     4977         1955  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_file = os.getenv(\"TICKERS\")\n",
    "pd.read_csv(ticker_file).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_file = os.getenv(\"TICKERS\")\n",
    "tickers = pd.read_csv(ticker_file).head(20)\n",
    "type(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting padas data frames\n",
    "\n",
    "+ From the [documentation](https://pandas.pydata.org/docs/user_guide/merging.html):\n",
    "\n",
    "> [`concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html#pandas.concat) makes a full copy of the data, and iteratively reusing `concat()` can create unnecessary copies. Collect all DataFrame or Series objects in a list before using `concat()`.\n",
    "\n",
    "+ We can string operation togethers using dot operations. Enclose the line in parenthesis and add linebreaks for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 00:00:00-05:00</td>\n",
       "      <td>93.398045</td>\n",
       "      <td>93.632126</td>\n",
       "      <td>90.362095</td>\n",
       "      <td>90.567802</td>\n",
       "      <td>6897900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-03 00:00:00-05:00</td>\n",
       "      <td>89.418686</td>\n",
       "      <td>90.362102</td>\n",
       "      <td>88.773195</td>\n",
       "      <td>89.801727</td>\n",
       "      <td>7864500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-04 00:00:00-05:00</td>\n",
       "      <td>89.340661</td>\n",
       "      <td>90.503969</td>\n",
       "      <td>89.014368</td>\n",
       "      <td>89.702423</td>\n",
       "      <td>3450700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-05 00:00:00-05:00</td>\n",
       "      <td>89.659845</td>\n",
       "      <td>90.546513</td>\n",
       "      <td>89.532165</td>\n",
       "      <td>89.964859</td>\n",
       "      <td>2842700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-06 00:00:00-05:00</td>\n",
       "      <td>90.929567</td>\n",
       "      <td>91.362261</td>\n",
       "      <td>90.688390</td>\n",
       "      <td>91.227486</td>\n",
       "      <td>2886100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>2024-01-25 00:00:00-05:00</td>\n",
       "      <td>84.713026</td>\n",
       "      <td>84.852144</td>\n",
       "      <td>83.947880</td>\n",
       "      <td>84.355293</td>\n",
       "      <td>1372600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>2024-01-26 00:00:00-05:00</td>\n",
       "      <td>84.544097</td>\n",
       "      <td>84.842203</td>\n",
       "      <td>83.918060</td>\n",
       "      <td>84.772644</td>\n",
       "      <td>1168000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>2024-01-29 00:00:00-05:00</td>\n",
       "      <td>84.395037</td>\n",
       "      <td>84.762709</td>\n",
       "      <td>83.540453</td>\n",
       "      <td>84.057175</td>\n",
       "      <td>1737600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>2024-01-30 00:00:00-05:00</td>\n",
       "      <td>84.086994</td>\n",
       "      <td>85.209873</td>\n",
       "      <td>83.679572</td>\n",
       "      <td>85.190002</td>\n",
       "      <td>1663600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>2024-01-31 00:00:00-05:00</td>\n",
       "      <td>85.458302</td>\n",
       "      <td>85.657039</td>\n",
       "      <td>83.759073</td>\n",
       "      <td>83.808754</td>\n",
       "      <td>2820000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23022 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date       Open       High        Low      Close  \\\n",
       "0    2013-12-02 00:00:00-05:00  93.398045  93.632126  90.362095  90.567802   \n",
       "1    2013-12-03 00:00:00-05:00  89.418686  90.362102  88.773195  89.801727   \n",
       "2    2013-12-04 00:00:00-05:00  89.340661  90.503969  89.014368  89.702423   \n",
       "3    2013-12-05 00:00:00-05:00  89.659845  90.546513  89.532165  89.964859   \n",
       "4    2013-12-06 00:00:00-05:00  90.929567  91.362261  90.688390  91.227486   \n",
       "...                        ...        ...        ...        ...        ...   \n",
       "2553 2024-01-25 00:00:00-05:00  84.713026  84.852144  83.947880  84.355293   \n",
       "2554 2024-01-26 00:00:00-05:00  84.544097  84.842203  83.918060  84.772644   \n",
       "2555 2024-01-29 00:00:00-05:00  84.395037  84.762709  83.540453  84.057175   \n",
       "2556 2024-01-30 00:00:00-05:00  84.086994  85.209873  83.679572  85.190002   \n",
       "2557 2024-01-31 00:00:00-05:00  85.458302  85.657039  83.759073  83.808754   \n",
       "\n",
       "       Volume  Dividends  Stock Splits ticker  \n",
       "0     6897900        0.0           0.0    MMM  \n",
       "1     7864500        0.0           0.0    MMM  \n",
       "2     3450700        0.0           0.0    MMM  \n",
       "3     2842700        0.0           0.0    MMM  \n",
       "4     2886100        0.0           0.0    MMM  \n",
       "...       ...        ...           ...    ...  \n",
       "2553  1372600        0.0           0.0    AFL  \n",
       "2554  1168000        0.0           0.0    AFL  \n",
       "2555  1737600        0.0           0.0    AFL  \n",
       "2556  1663600        0.0           0.0    AFL  \n",
       "2557  2820000        0.0           0.0    AFL  \n",
       "\n",
       "[23022 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px_list = list()\n",
    "for k, row in tickers.iterrows():\n",
    "    #print(f'The row is {row[\"ticker\"]}\\n\\n')\n",
    "    stock = yf.Ticker(row['ticker'])\n",
    "    px = (stock\n",
    "          .history(start = '2013-12-01',\n",
    "                   end = '2024-02-01')\n",
    "                   .reset_index()\n",
    "                   .assign(ticker=row['ticker']))\n",
    "    if px.shape[0] == 0:\n",
    "    print(f'No data for {row[\"ticker\"]}')  # Validate: do not fail silently.\n",
    "    px_list.append(px)\n",
    "\n",
    "px_dt = pd.concat(px_list, axis = 0) # concatenating, axis = 0 is on df on top of the other. in pandas axis = 0 is by rows\n",
    "px_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-02 00:00:00-05:00</td>\n",
       "      <td>31.886691</td>\n",
       "      <td>32.011633</td>\n",
       "      <td>31.577622</td>\n",
       "      <td>31.820930</td>\n",
       "      <td>4321900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-03 00:00:00-05:00</td>\n",
       "      <td>32.307550</td>\n",
       "      <td>33.050628</td>\n",
       "      <td>32.202335</td>\n",
       "      <td>32.859928</td>\n",
       "      <td>9480100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-04 00:00:00-05:00</td>\n",
       "      <td>32.715264</td>\n",
       "      <td>33.070364</td>\n",
       "      <td>32.419346</td>\n",
       "      <td>32.662655</td>\n",
       "      <td>5309200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-05 00:00:00-05:00</td>\n",
       "      <td>32.498247</td>\n",
       "      <td>32.925683</td>\n",
       "      <td>32.254938</td>\n",
       "      <td>32.721828</td>\n",
       "      <td>5449100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-06 00:00:00-05:00</td>\n",
       "      <td>32.991443</td>\n",
       "      <td>33.866043</td>\n",
       "      <td>32.912532</td>\n",
       "      <td>33.767403</td>\n",
       "      <td>7285800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>2024-01-25 00:00:00-05:00</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>165.210007</td>\n",
       "      <td>163.199997</td>\n",
       "      <td>165.130005</td>\n",
       "      <td>4465800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>2024-01-26 00:00:00-05:00</td>\n",
       "      <td>165.270004</td>\n",
       "      <td>165.860001</td>\n",
       "      <td>163.500000</td>\n",
       "      <td>164.399994</td>\n",
       "      <td>4654300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>2024-01-29 00:00:00-05:00</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>166.759995</td>\n",
       "      <td>163.679993</td>\n",
       "      <td>163.910004</td>\n",
       "      <td>4704100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>2024-01-30 00:00:00-05:00</td>\n",
       "      <td>164.220001</td>\n",
       "      <td>164.979996</td>\n",
       "      <td>163.259995</td>\n",
       "      <td>164.919998</td>\n",
       "      <td>3819600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>2024-01-31 00:00:00-05:00</td>\n",
       "      <td>165.750000</td>\n",
       "      <td>165.860001</td>\n",
       "      <td>163.949997</td>\n",
       "      <td>164.399994</td>\n",
       "      <td>4993900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2558 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date        Open        High         Low  \\\n",
       "0    2013-12-02 00:00:00-05:00   31.886691   32.011633   31.577622   \n",
       "1    2013-12-03 00:00:00-05:00   32.307550   33.050628   32.202335   \n",
       "2    2013-12-04 00:00:00-05:00   32.715264   33.070364   32.419346   \n",
       "3    2013-12-05 00:00:00-05:00   32.498247   32.925683   32.254938   \n",
       "4    2013-12-06 00:00:00-05:00   32.991443   33.866043   32.912532   \n",
       "...                        ...         ...         ...         ...   \n",
       "2553 2024-01-25 00:00:00-05:00  164.000000  165.210007  163.199997   \n",
       "2554 2024-01-26 00:00:00-05:00  165.270004  165.860001  163.500000   \n",
       "2555 2024-01-29 00:00:00-05:00  165.850006  166.759995  163.679993   \n",
       "2556 2024-01-30 00:00:00-05:00  164.220001  164.979996  163.259995   \n",
       "2557 2024-01-31 00:00:00-05:00  165.750000  165.860001  163.949997   \n",
       "\n",
       "           Close   Volume  Dividends  Stock Splits ticker  \n",
       "0      31.820930  4321900        0.0           0.0   ABBV  \n",
       "1      32.859928  9480100        0.0           0.0   ABBV  \n",
       "2      32.662655  5309200        0.0           0.0   ABBV  \n",
       "3      32.721828  5449100        0.0           0.0   ABBV  \n",
       "4      33.767403  7285800        0.0           0.0   ABBV  \n",
       "...          ...      ...        ...           ...    ...  \n",
       "2553  165.130005  4465800        0.0           0.0   ABBV  \n",
       "2554  164.399994  4654300        0.0           0.0   ABBV  \n",
       "2555  163.910004  4704100        0.0           0.0   ABBV  \n",
       "2556  164.919998  3819600        0.0           0.0   ABBV  \n",
       "2557  164.399994  4993900        0.0           0.0   ABBV  \n",
       "\n",
       "[2558 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px_dt[px_dt['ticker'] =='ABBV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold final results\n",
    "px_list = list()\n",
    "\n",
    "for k, row in tickers.iterrows():  # Produces an iterator that returns index and row\n",
    "\n",
    "    stock = yf.Ticker(row['ticker'])\n",
    "    print(f'Processing {row[\"ticker\"]}')\n",
    "    \n",
    "    px = (stock\n",
    "          .history(start = pd.to_datetime(\"2013-12-01\"), \n",
    "                   end = pd.to_datetime(\"2024-02-01\"))\n",
    "          .reset_index()   # Reset index to get date as a column\n",
    "          .assign(ticker = row['ticker']))    # Add ticker\n",
    "    \n",
    "    if px.shape[0] == 0:\n",
    "        print(f'No data for {row[\"ticker\"]}')  # Validate: do not fail silently.\n",
    "        continue\n",
    "    print(f'Downloaded {px.shape}.')\n",
    "    px_list.append(px)\n",
    "px_dt = pd.concat(px_list, axis = 0)\n",
    "print(f'Final shape {px_dt.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability\n",
    "\n",
    "+ Keppelman (2017) defines *reliability* as:\n",
    "\n",
    "    - A system should continue to work correctly. \n",
    "    - To work correctly means performing the correct function at the desired level of performance, even in the face of adversity such as hardware or software faults, and even human error. \n",
    "\n",
    "+ *Faults* are things that can go wrong.\n",
    "+ Sytems that can cope with (certain types of) faults are called *fault-tolerant* or *resilient*.\n",
    "+ A fault is different than a failure. \n",
    "    \n",
    "    - A *fault* occurs when a component of the system deviates from spec.\n",
    "    - A *failure*  is when the system stops providing the required service to the user.\n",
    "\n",
    "+ In our simple example, we handle the fault that occurs when one ticker is not found and log it using *warning*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data in CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We have some data. How do we store it?\n",
    "+ We can compare two options, CSV and Parqruet, by measuring their performance:\n",
    "\n",
    "    - Time to save.\n",
    "    - Space required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scan the directory, traverese the directory and total the file sizes in the directopry to measure tuime and space each files requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_size(path='.'):\n",
    "    '''Returns the total size of files contained in path.'''\n",
    "    total = 0\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size # fix value of total and get it added to the function\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.getenv(\"TEMP_DATA\") # check .env for the directory etc its in there.\n",
    "os.makedirs(temp, exist_ok=True) # it will create directory if it doesnt exist. if it does exist then nothing will happen\n",
    "stock_path = os.path.join(temp, \"stock_px.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to dt ((23022, 9))csv took 0.8207588195800781 seconds.\n",
      "Csv file size 2.759911 MB\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "px_dt.to_csv(stock_path, index = False)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Writing to dt ({px_dt.shape})csv took {end - start} seconds.')\n",
    "print(f'Csv file size { os.path.getsize(stock_path)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data to Parquet\n",
    "\n",
    "### Dask \n",
    "\n",
    "We can work with with large data sets and parquet files. In fact, recent versions of pandas support pyarrow data types and future versions will require a pyarrow backend. The pyarrow library is an interface between Python and the Appache Arrow project. The [parquet data format](https://parquet.apache.org/) and [Arrow](https://arrow.apache.org/docs/python/parquet.html) are projects of the Apache Foundation.\n",
    "\n",
    "However, Dask is much more than an interface to Arrow: Dask provides parallel and distributed computing on pandas-like dataframes. It is also relatively easy to use, bridging a gap between pandas and Spark. \n",
    "\n",
    "Pd to parquet uses a simple partiotion, but with dask we can use the partitions as well. \n",
    "\n",
    "Notice the difference in time and space between parquet and dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask # will basically give access to parquet dataformat.\n",
    "dask.config.set({'dataframe.query-planning': True})\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dd ((23022, 9)) to parquet took 0.10099649429321289 seconds.\n",
      "Parquet file size 1.0615679999999998 MB\n"
     ]
    }
   ],
   "source": [
    "px_dd = dd.from_pandas(px_dt, npartitions = len(tickers))\n",
    "parquet_path = os.path.join(temp, \"stock_px.parquet\")\n",
    "\n",
    "start = time.time()\n",
    "px_dd.to_parquet(parquet_path, engine = \"pyarrow\")\n",
    "end = time.time()\n",
    "\n",
    "print(f'Writing dd ({px_dt.shape}) to parquet took {end - start} seconds.')\n",
    "print(f'Parquet file size { get_dir_size(parquet_path)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet files and Dask Dataframes\n",
    "\n",
    "+ Parquet files are immutable: once written, they cannot be modified.\n",
    "+ Dask DataFrames are a useful implementation to manipulate data stored in parquets.\n",
    "+ Parquet and Dask are not the same: parquet is a file format that can be accessed by many applications and programming languages (Python, R, PowerBI, etc.), while Dask is a package in Python to work with large datasets using distributed computation.\n",
    "+ **Dask is not for everything** (see [Dask DataFrames Best Practices](https://docs.dask.org/en/stable/dataframe-best-practices.html)). \n",
    "\n",
    "    - Consider cases suchas small to larrge joins, where the small dataframe fits in memory, but the large one does not. \n",
    "    - If possible, use pandas: reduce, then use pandas.\n",
    "    - Pandas performance tips apply to Dask.\n",
    "    - Use the index: it is beneficial to have a well-defined index in Dask DataFrames, as it may speed up searching (filtering) the data. A one-dimensional index is allowed.\n",
    "    - Avoid (or minimize) full-data shuffling: indexing is an expensive operations. \n",
    "    - Some joins are more expensive than others. \n",
    "\n",
    "        * Not expensive:\n",
    "\n",
    "            - Join a Dask DataFrame with a pandas DataFrame.\n",
    "            - Join a Dask DataFrame with another Dask DataFrame of a single partition.\n",
    "            - Join Dask DataFrames along their indexes.\n",
    "\n",
    "        * Expensive:\n",
    "\n",
    "            - Join Dask DataFrames along columns that are not their index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we store prices?\n",
    "\n",
    "+ We can store our data as a single blob. This can be difficult to maintain, especially because parquet files are immutable.\n",
    "+ Strategy: organize data files by ticker and date. Update only latest month. named spaces, create a directory for stock and a parquet file per year, and the current uyear we reqrite (parquet is immutable). That is why the partitions are important. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")\n",
    "\n",
    "for ticker in px_dt.ticker.unique():\n",
    "    ticker_dt = px_dt[px_dt.ticker == ticker] # subset df ticker by ticker and assign a year.\n",
    "    ticker_dt = ticker_dt.assign(year = ticker_dt.Date.dt.year) # uses the dt accessor to access the data frame. \n",
    "    for yr in ticker_dt.year.unique():\n",
    "        yr_dt = ticker_dt[ticker_dt.year == yr]\n",
    "        yr_path = os.path.join(PRICE_DATA, ticker, f\"{ticker}_{yr}.parquet\")\n",
    "        os.makedirs(os.path.dirname(yr_path), exist_ok=True)\n",
    "        yr_dt.to_parquet(yr_path, engine = \"pyarrow\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2013\n",
       "1       2013\n",
       "2       2013\n",
       "3       2013\n",
       "4       2013\n",
       "        ... \n",
       "2553    2024\n",
       "2554    2024\n",
       "2555    2024\n",
       "2556    2024\n",
       "2557    2024\n",
       "Name: Date, Length: 23022, dtype: int32"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px_dt['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below lines are the same \n",
    "# px['year'] = px_dt['Date'].dt.year\n",
    "# px_dt = px_dt.assign(year = px_dt.Date.dt.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would we want to store data this way?\n",
    "\n",
    "+ Easier to maintain. We do not update old data, only recent data.\n",
    "+ We can also access all files as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Transform and Save "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "+ Parquet files can be read individually or as a collection.\n",
    "+ `dd.read_parquet()` can take a list (collection) of files as input.\n",
    "+ Use `glob` to get the collection of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "parquet_files = glob(os.path.join(PRICE_DATA, '*/*.parquet'))\n",
    "#parquet_files = glob(PRICE_DATA+\"/**/*.parquet/*.parquet\")\n",
    "dd_px = dd.read_parquet(parquet_files).set_index(\"ticker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask_expr.expr.DataFrame: expr=SetIndex(frame=ReadParquet(05f1383), _other=ticker, options={})>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_px # dask is a big data library, so it has lazy execution. Thats why it does not showing up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2013-12-02 00:00:00-05:00</td>\n",
       "      <td>31.886691</td>\n",
       "      <td>32.011633</td>\n",
       "      <td>31.577622</td>\n",
       "      <td>31.820930</td>\n",
       "      <td>4321900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2013-12-03 00:00:00-05:00</td>\n",
       "      <td>32.307550</td>\n",
       "      <td>33.050628</td>\n",
       "      <td>32.202335</td>\n",
       "      <td>32.859928</td>\n",
       "      <td>9480100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2013-12-04 00:00:00-05:00</td>\n",
       "      <td>32.715264</td>\n",
       "      <td>33.070364</td>\n",
       "      <td>32.419346</td>\n",
       "      <td>32.662655</td>\n",
       "      <td>5309200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2013-12-05 00:00:00-05:00</td>\n",
       "      <td>32.498247</td>\n",
       "      <td>32.925683</td>\n",
       "      <td>32.254938</td>\n",
       "      <td>32.721828</td>\n",
       "      <td>5449100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2013-12-06 00:00:00-05:00</td>\n",
       "      <td>32.991443</td>\n",
       "      <td>33.866043</td>\n",
       "      <td>32.912532</td>\n",
       "      <td>33.767403</td>\n",
       "      <td>7285800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>2024-01-25 00:00:00-05:00</td>\n",
       "      <td>92.247775</td>\n",
       "      <td>94.706929</td>\n",
       "      <td>92.080554</td>\n",
       "      <td>94.411835</td>\n",
       "      <td>6122900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>2024-01-26 00:00:00-05:00</td>\n",
       "      <td>94.647914</td>\n",
       "      <td>95.316805</td>\n",
       "      <td>94.224940</td>\n",
       "      <td>94.421669</td>\n",
       "      <td>3720200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>2024-01-29 00:00:00-05:00</td>\n",
       "      <td>94.431509</td>\n",
       "      <td>95.306967</td>\n",
       "      <td>93.880661</td>\n",
       "      <td>94.805298</td>\n",
       "      <td>3800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>2024-01-30 00:00:00-05:00</td>\n",
       "      <td>94.598729</td>\n",
       "      <td>94.933178</td>\n",
       "      <td>93.231440</td>\n",
       "      <td>94.185593</td>\n",
       "      <td>3200500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>2024-01-31 00:00:00-05:00</td>\n",
       "      <td>94.372490</td>\n",
       "      <td>94.372490</td>\n",
       "      <td>92.621573</td>\n",
       "      <td>92.808464</td>\n",
       "      <td>6906800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23022 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date       Open       High        Low      Close  \\\n",
       "ticker                                                                         \n",
       "ABBV   2013-12-02 00:00:00-05:00  31.886691  32.011633  31.577622  31.820930   \n",
       "ABBV   2013-12-03 00:00:00-05:00  32.307550  33.050628  32.202335  32.859928   \n",
       "ABBV   2013-12-04 00:00:00-05:00  32.715264  33.070364  32.419346  32.662655   \n",
       "ABBV   2013-12-05 00:00:00-05:00  32.498247  32.925683  32.254938  32.721828   \n",
       "ABBV   2013-12-06 00:00:00-05:00  32.991443  33.866043  32.912532  33.767403   \n",
       "...                          ...        ...        ...        ...        ...   \n",
       "MMM    2024-01-25 00:00:00-05:00  92.247775  94.706929  92.080554  94.411835   \n",
       "MMM    2024-01-26 00:00:00-05:00  94.647914  95.316805  94.224940  94.421669   \n",
       "MMM    2024-01-29 00:00:00-05:00  94.431509  95.306967  93.880661  94.805298   \n",
       "MMM    2024-01-30 00:00:00-05:00  94.598729  94.933178  93.231440  94.185593   \n",
       "MMM    2024-01-31 00:00:00-05:00  94.372490  94.372490  92.621573  92.808464   \n",
       "\n",
       "         Volume  Dividends  Stock Splits  year  \n",
       "ticker                                          \n",
       "ABBV    4321900        0.0           0.0  2013  \n",
       "ABBV    9480100        0.0           0.0  2013  \n",
       "ABBV    5309200        0.0           0.0  2013  \n",
       "ABBV    5449100        0.0           0.0  2013  \n",
       "ABBV    7285800        0.0           0.0  2013  \n",
       "...         ...        ...           ...   ...  \n",
       "MMM     6122900        0.0           0.0  2024  \n",
       "MMM     3720200        0.0           0.0  2024  \n",
       "MMM     3800000        0.0           0.0  2024  \n",
       "MMM     3200500        0.0           0.0  2024  \n",
       "MMM     6906800        0.0           0.0  2024  \n",
       "\n",
       "[23022 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_px.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2013-12-02 00:00:00-05:00</td>\n",
       "      <td>31.886691</td>\n",
       "      <td>32.011633</td>\n",
       "      <td>31.577622</td>\n",
       "      <td>31.820930</td>\n",
       "      <td>4321900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2013-12-03 00:00:00-05:00</td>\n",
       "      <td>32.307550</td>\n",
       "      <td>33.050628</td>\n",
       "      <td>32.202335</td>\n",
       "      <td>32.859928</td>\n",
       "      <td>9480100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2013-12-04 00:00:00-05:00</td>\n",
       "      <td>32.715264</td>\n",
       "      <td>33.070364</td>\n",
       "      <td>32.419346</td>\n",
       "      <td>32.662655</td>\n",
       "      <td>5309200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2013-12-05 00:00:00-05:00</td>\n",
       "      <td>32.498247</td>\n",
       "      <td>32.925683</td>\n",
       "      <td>32.254938</td>\n",
       "      <td>32.721828</td>\n",
       "      <td>5449100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2013-12-06 00:00:00-05:00</td>\n",
       "      <td>32.991443</td>\n",
       "      <td>33.866043</td>\n",
       "      <td>32.912532</td>\n",
       "      <td>33.767403</td>\n",
       "      <td>7285800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2024-01-25 00:00:00-05:00</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>165.210007</td>\n",
       "      <td>163.199997</td>\n",
       "      <td>165.130005</td>\n",
       "      <td>4465800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2024-01-26 00:00:00-05:00</td>\n",
       "      <td>165.270004</td>\n",
       "      <td>165.860001</td>\n",
       "      <td>163.500000</td>\n",
       "      <td>164.399994</td>\n",
       "      <td>4654300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2024-01-29 00:00:00-05:00</td>\n",
       "      <td>165.850006</td>\n",
       "      <td>166.759995</td>\n",
       "      <td>163.679993</td>\n",
       "      <td>163.910004</td>\n",
       "      <td>4704100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2024-01-30 00:00:00-05:00</td>\n",
       "      <td>164.220001</td>\n",
       "      <td>164.979996</td>\n",
       "      <td>163.259995</td>\n",
       "      <td>164.919998</td>\n",
       "      <td>3819600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>2024-01-31 00:00:00-05:00</td>\n",
       "      <td>165.750000</td>\n",
       "      <td>165.860001</td>\n",
       "      <td>163.949997</td>\n",
       "      <td>164.399994</td>\n",
       "      <td>4993900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2558 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date        Open        High         Low  \\\n",
       "ticker                                                                 \n",
       "ABBV   2013-12-02 00:00:00-05:00   31.886691   32.011633   31.577622   \n",
       "ABBV   2013-12-03 00:00:00-05:00   32.307550   33.050628   32.202335   \n",
       "ABBV   2013-12-04 00:00:00-05:00   32.715264   33.070364   32.419346   \n",
       "ABBV   2013-12-05 00:00:00-05:00   32.498247   32.925683   32.254938   \n",
       "ABBV   2013-12-06 00:00:00-05:00   32.991443   33.866043   32.912532   \n",
       "...                          ...         ...         ...         ...   \n",
       "ABBV   2024-01-25 00:00:00-05:00  164.000000  165.210007  163.199997   \n",
       "ABBV   2024-01-26 00:00:00-05:00  165.270004  165.860001  163.500000   \n",
       "ABBV   2024-01-29 00:00:00-05:00  165.850006  166.759995  163.679993   \n",
       "ABBV   2024-01-30 00:00:00-05:00  164.220001  164.979996  163.259995   \n",
       "ABBV   2024-01-31 00:00:00-05:00  165.750000  165.860001  163.949997   \n",
       "\n",
       "             Close   Volume  Dividends  Stock Splits  year  \n",
       "ticker                                                      \n",
       "ABBV     31.820930  4321900        0.0           0.0  2013  \n",
       "ABBV     32.859928  9480100        0.0           0.0  2013  \n",
       "ABBV     32.662655  5309200        0.0           0.0  2013  \n",
       "ABBV     32.721828  5449100        0.0           0.0  2013  \n",
       "ABBV     33.767403  7285800        0.0           0.0  2013  \n",
       "...            ...      ...        ...           ...   ...  \n",
       "ABBV    165.130005  4465800        0.0           0.0  2024  \n",
       "ABBV    164.399994  4654300        0.0           0.0  2024  \n",
       "ABBV    163.910004  4704100        0.0           0.0  2024  \n",
       "ABBV    164.919998  3819600        0.0           0.0  2024  \n",
       "ABBV    164.399994  4993900        0.0           0.0  2024  \n",
       "\n",
       "[2558 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_px[dd_px.index == \"ABBV\"].compute() # or use ticker instead of index. if you do not set index as ticker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "+ This transformation step will create a *Features* data set. In our case, features will be stock returns (we obtained prices).\n",
    "+ Dask dataframes work like pandas dataframes: in particular, we can perform groupby and apply operations.\n",
    "+ Notice the use of [an anonymous (lambda) function](https://realpython.com/python-lambda/) in the apply statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramin\\AppData\\Local\\Temp\\ipykernel_12484\\3091835559.py:2: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  dd_rets = (dd_px.groupby('ticker', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# This is a map reduce operation. We need returns, so we need a lagged price series, and get the ratios to get the returns, so we group by and apply.\n",
    "dd_rets = (dd_px.groupby('ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(Close_lag_1 = x['Close'].shift(1))\n",
    ").assign(\n",
    "    returns = lambda x: x['Close']/x['Close_lag_1'] - 1\n",
    ").assign(\n",
    "    positive_return = lambda x: (x['returns'] > 0)*1\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Exection\n",
    "\n",
    "What does `dd_rets` contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_rets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Dask is a lazy execution framework: commands will not execute until they are required. \n",
    "+ To trigger an execution in dask use `.compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_rets.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "\n",
    "+ Apply transformations to calculate daily returns\n",
    "+ Store the enriched data, the silver dataset, in a new directory.\n",
    "+ Should we keep the same namespace? All columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = os.getenv(\"FEATURES_DATA\")\n",
    "dd_rets.to_parquet(features_path, engine = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few notes\n",
    "\n",
    "# Jupyter? \n",
    "\n",
    "+ We have drafted our code in a Jupyter Notebook. \n",
    "+ Finalized code should be written in Python modules.\n",
    "\n",
    "## Object oriented programming?\n",
    "\n",
    "+ We can use classes to keep parameters and functions together.\n",
    "+ We *could* use Object Oriented Programming, but parallelization of data manipulation and modelling tasks benefits from *Functional Programming*.\n",
    "+ An Idea: \n",
    "\n",
    "    - [Data Oriented Programming](https://blog.klipse.tech/dop/2022/06/22/principles-of-dop.html).\n",
    "    - Use the class to bundle together parameters and functions.\n",
    "    - Use stateless operations and treat all data objects as immutable (we do not modify them, we overwrite them).\n",
    "    - Take advantage of [`@staticmethod`](https://realpython.com/instance-class-and-static-methods-demystified/).\n",
    "\n",
    "The code is in `./src/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original design was:\n",
    "\n",
    "![](./img/target_pipeline_manager.png)\n",
    "\n",
    "Our resulting interface is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from data_manager import DataManager\n",
    "dm = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.download_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.featurize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
